import h5py
from pyannote.database.util import get_unique_identifier
from pyannote.core import SlidingWindow, SlidingWindowFeature
import os
import numpy as np

from pyannote.database import get_protocol, FileFinder
protocol = get_protocol('AMI.SpeakerSpotting.MixHeadset', progress=True)
from pyannote.core import Annotation,Segment, Timeline

REFERENCE = {}
for current_file in protocol.development():
    uri = current_file['uri']
    if uri not in REFERENCE:
        REFERENCE[uri] = Annotation(uri=uri)
    REFERENCE[uri].update(current_file['annotation'])
   
from pyannote.parser import MDTMParser
sad_dev = '/people/yin/projects/online_clustering/spotting/AMI.SpeakerSpotting.MixHeadset.development.mdtm'
parser_dev = MDTMParser()
annotations_dev = parser_dev.read(sad_dev)
SAD = {}
for item in protocol.development():
    uri = item['uri']
    SAD[uri] = annotations_dev(uri=uri, modality="speaker").get_timeline().support()

    
class PyannoteFeatureExtractionError(Exception):
    pass
class Precomputed(object):
    """Load precomputed features from HDF5 file
    Parameters
    ----------
    features_h5 : str
        Path to HDF5 file generated by script 'feature_extraction.py'.
    """

    @staticmethod
    def get_path(root_dir, item):
        uri = get_unique_identifier(item)
        file_name = uri.split('.')[0].split('/')[1]
        path = '{root_dir}/{file_name}/audio/{file_name}.Mix-Headset.hdf5'.format(root_dir=root_dir,file_name=file_name)
        return path

    def __init__(self, root_dir=None):
        super(Precomputed, self).__init__()
        self.root_dir = root_dir

        start = 0
        duration = 2.5
        step = 2
        self.sliding_window_ = SlidingWindow(
            start=start, duration=duration, step=step)

    def sliding_window(self):
        return self.sliding_window_


    def __call__(self, item):

        path = self.get_path(self.root_dir, item)
        if not os.path.exists(path):
            uri = get_unique_identifier(item)
            print(uri)
            msg = 'No precomputed features for "{uri}".'
            raise PyannoteFeatureExtractionError(msg.format(uri=uri))

        f = h5py.File(path)
        data = np.array(f['array'])
        f.close()

        return SlidingWindowFeature(data, self.sliding_window_)
 

precomputed = Precomputed('/vol/work3/barras/ami/ivectors/ami_MixHeadset')


# enrolment consists in summing all relevant embeddings
def speaker_spotting_enrol(current_enrolment):
    enrol_with = current_enrolment['enrol_with']
    embeddings = precomputed(current_enrolment)
    return embeddings.crop(enrol_with)

models = {}
for current_enrolment in protocol.development_enrolment():
    model_id = current_enrolment.pop('model_id')
    models[model_id] = speaker_spotting_enrol(current_enrolment)
    
from pyannote.core import SlidingWindow, SlidingWindowFeature
from pyannote.audio.embedding.utils import cdist

# trial consists in comparing each embedding to the target embedding
def speaker_spotting_try(current_trial):

    # target model
    model = models[current_trial['model_id']]
    # where to look for this target
    try_with = current_trial['try_with']
    
    # precomputed embedding
    embeddings = precomputed(current_trial)
    
    # find index of first and last embedding fully included in 'try_with'
    indices = embeddings.sliding_window.crop(try_with, mode='strict')
    first, last = indices[0], indices[-1]
    
    speech_timeline = SAD[current_trial['uri']]
    indices_speech = embeddings.sliding_window.crop(speech_timeline, mode='center')
    
    # compare all embeddings to target model
    data = 2. - np.mean(cdist(embeddings.data, model, metric='cosine'),axis=1, keepdims=True)
    score = np.zeros((len(embeddings.data)+2, 1))
    indices_speech = [indice for indice in indices_speech if indice < len(data)]
    score[indices_speech] = data[indices_speech]
    score = score[first:last+1] 
    sliding_window = SlidingWindow(start=embeddings.sliding_window[first].start,
                                   duration=embeddings.sliding_window.duration,
                                   step=embeddings.sliding_window.step)
    
    return SlidingWindowFeature(score, sliding_window)


def process_score(scores):
    min_score = 0
    res = []
    for (window, score) in scores:
        if score > min_score:
            res.append([window.end, score[0]])
            min_score = score[0]
    return res

def process_trial(trial, scores):
    res = {}
    pscores = process_score(scores)
    res['uri'] = trial['uri']
    res['model_id'] = trial['model_id']
    res['scores'] = pscores
    return res

from pyannote.metrics.spotting import LowLatencySpeakerSpotting
metric = LowLatencySpeakerSpotting(thresholds=np.linspace(0, 2, 50))
llss = []
for current_trial in protocol.development_trial():
    reference = current_trial.pop('reference')
    hypothesis = speaker_spotting_try(current_trial)
    llss.append(process_trial(current_trial, hypothesis))
    metric(reference, hypothesis)
    
import simplejson as json
with open('ivector_dev_no_clustering_pyannote_sad.json', 'w') as outfile:  
    json.dump(llss, outfile)